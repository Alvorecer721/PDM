{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuyixuan/opt/anaconda3/envs/goldfish/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1231 examples [00:00, 4617.35 examples/s]\n"
     ]
    }
   ],
   "source": [
    "unmatch = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/Users/xuyixuan/Downloads/Project/PDM/PDM/data/gutenberg_en_8k/unmatch.jsonl\",  \n",
    "    split=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'input_ids'],\n",
       "    num_rows: 1231\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\")\n",
    "tokenizer.model_max_length = 200_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_fn = partial(\n",
    "   tokenizer, \n",
    "   truncation=False, \n",
    "   padding=False, \n",
    "   add_special_tokens=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unmatch(unmatch, idx):\n",
    "    a = tokenize_fn(text=unmatch[idx]['text']).input_ids\n",
    "    b = unmatch[idx]['input_ids']\n",
    "    s = SequenceMatcher(None, a, b)\n",
    "    for tag, i1, i2, j1, j2 in s.get_opcodes():\n",
    "        if tag == 'replace':\n",
    "            print('{:<7} a[{:>4}:{:>4}] --> b[{:>4}:{:>4}] {!r:>12} --> {!r:<20} Replace [{:^20}] with [{:^20}]'.format(\n",
    "                tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2], tokenizer.decode(a[i1:i2]), tokenizer.decode(b[j1:j2])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace a[3199:3201] --> b[3199:3201]  [596, 1002] --> [364, 68182]         Replace [       'spect       ] with [       'spect       ]\n",
      "replace a[5007:5009] --> b[5007:5010]  [596, 2972] --> [364, 2203, 974]     Replace [       'spose       ] with [       'spose       ]\n"
     ]
    }
   ],
   "source": [
    "find_unmatch(unmatch, 112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'ve\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([364, 588])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goldfish",
   "language": "python",
   "name": "goldish"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
