{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/mloscratch/homes/yixuan/PDM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from src.verbatim_eval.edit_distance import compute_ngram_distance_damerau_levenshtein\n",
    "from src.verbatim_eval.LCS import find_longest_common_substrings\n",
    "from src.verbatim_eval.exact_match import CommonSubstringMatcher\n",
    "from src.gutenberg.config import DataConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sparse_inference_data(base_dir, rep):\n",
    "    file_path = f\"{base_dir}/rep_{rep}\"\n",
    "    return load_dataset('json', data_files=f\"{file_path}/rank*.jsonl\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_lcs_lengths(base_dir, reptitions):\n",
    "    \"\"\"\n",
    "    Calculate average LCS lengths for multiple models with data split into train/val/test\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    base_dir : str\n",
    "        Base directory containing all model results\n",
    "    model_ids : list\n",
    "        List of model identifiers to process\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary mapping model names to their results with split information\n",
    "    \"\"\"\n",
    "\n",
    "    results = {}\n",
    "    for rep in reptitions:\n",
    "        data = load_sparse_inference_data(base_dir, rep)\n",
    "        \n",
    "        lcs_res = find_longest_common_substrings(\n",
    "            data['true_suffix'], \n",
    "            data['generated_suffix']\n",
    "        )\n",
    "       \n",
    "        results[f\"rep_{rep}\"] = lcs_res.max_length.mean()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up Numba JIT...\n",
      "Processing 500 sequence pairs in parallel...\n",
      "Time taken: 0.08 seconds\n"
     ]
    }
   ],
   "source": [
    "calc_avg_lcs_lengths(base_dir='/mloscratch/homes/yixuan/PDM/inference/sparse_gutenberg_standard', \n",
    "                     reptitions=DataConfig.repetitions[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 500 examples [00:00, 4636.88 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up Numba JIT...\n",
      "Processing 500 sequence pairs in parallel...\n",
      "Time taken: 0.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 500 examples [00:00, 5690.11 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up Numba JIT...\n",
      "Processing 500 sequence pairs in parallel...\n",
      "Time taken: 0.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 500 examples [00:00, 5820.89 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up Numba JIT...\n",
      "Processing 500 sequence pairs in parallel...\n",
      "Time taken: 0.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 500 examples [00:00, 5830.02 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up Numba JIT...\n",
      "Processing 500 sequence pairs in parallel...\n",
      "Time taken: 0.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 500 examples [00:00, 5673.71 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up Numba JIT...\n",
      "Processing 500 sequence pairs in parallel...\n",
      "Time taken: 0.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 500 examples [00:00, 5710.47 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up Numba JIT...\n",
      "Processing 500 sequence pairs in parallel...\n",
      "Time taken: 0.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 500 examples [00:00, 5196.17 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up Numba JIT...\n",
      "Processing 500 sequence pairs in parallel...\n",
      "Time taken: 0.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 500 examples [00:00, 5928.88 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up Numba JIT...\n",
      "Processing 500 sequence pairs in parallel...\n",
      "Time taken: 0.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 500 examples [00:00, 5922.69 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up Numba JIT...\n",
      "Processing 500 sequence pairs in parallel...\n",
      "Time taken: 0.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 500 examples [00:00, 5795.08 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up Numba JIT...\n",
      "Processing 500 sequence pairs in parallel...\n",
      "Time taken: 0.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 500 examples [00:00, 5800.48 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up Numba JIT...\n",
      "Processing 500 sequence pairs in parallel...\n",
      "Time taken: 0.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 500 examples [00:00, 5884.25 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up Numba JIT...\n",
      "Processing 500 sequence pairs in parallel...\n",
      "Time taken: 0.08 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rep_1': 4.024,\n",
       " 'rep_2': 3.786,\n",
       " 'rep_3': 3.73,\n",
       " 'rep_4': 3.802,\n",
       " 'rep_8': 4.076,\n",
       " 'rep_16': 4.12,\n",
       " 'rep_24': 4.222,\n",
       " 'rep_32': 5.024,\n",
       " 'rep_48': 5.216,\n",
       " 'rep_64': 5.454,\n",
       " 'rep_96': 5.582,\n",
       " 'rep_128': 7.316}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_avg_lcs_lengths(base_dir='/mloscratch/homes/yixuan/PDM/inference/sparse_gutenberg_K_50_H_13', \n",
    "                     reptitions=DataConfig.repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
